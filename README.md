# ğŸ›’ Retail Sales Data Pipeline & Dashboard

**A beginner-friendly Data Engineering project** built with Python, Pandas, SQLite, and Plotly Dash.  
This project demonstrates how to clean, transform, store, and visualize retail sales data end-to-end â€” without using any cloud tools.

---

## ğŸ“Œ Project Overview

This project simulates a small-scale retail data pipeline from CSV files to a structured database and interactive dashboard. It's perfect for learning the foundational workflow of a Data Engineer:

- ğŸ§¹ Data Cleaning with Pandas  
- ğŸ—ƒï¸ Database Loading using SQLite  
- ğŸ“Š Dashboard Visualization with Plotly Dash  

---

## ğŸ›  Tech Stack

| Tool         | Role                          |
|--------------|-------------------------------|
| Python       | Core scripting                |
| Pandas       | Data cleaning & transformation|
| SQLite3      | Lightweight relational DB     |
| Plotly Dash  | Web-based dashboard           |
| VS Code      | IDE for development           |

---

## ğŸ” Project Workflow

### 1. ğŸ“¥ Data Ingestion

- Input files: `sales.csv`, `products.csv`, `stores.csv`
- Initial inspection for nulls, duplicates, and inconsistent formats

### 2. ğŸ§¼ Data Cleaning

- Removed rows with missing or invalid data
- Converted price columns to float
- Standardized `date` fields to `YYYY-MM-DD` format
- Output: `*_cleaned.csv` files

### 3. ğŸ—ƒï¸ SQLite Database

- Created SQLite DB: `retail.db`
- Tables:
  - `sales`
  - `products`
  - `stores`
- Inserted cleaned data into respective tables using Pythonâ€™s `sqlite3` module

### 4. ğŸ“Š Dashboard (Optional but Powerful)

- Built an interactive dashboard using Plotly Dash:
  - Total sales by product
  - Sales trends over time
  - Sales by store
- Launch it by running `dashboard.py`

---

## ğŸ“ Project Structure

retail-data-engineering/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ sales.csv
â”‚   â”œâ”€â”€ products.csv
â”‚   â”œâ”€â”€ stores.csv
â”‚   â”œâ”€â”€ sales_cleaned.csv
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ retail.db
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”œâ”€â”€ load_to_sqlite.py
â”‚   â””â”€â”€ dashboard.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt


---

## ğŸ’¡ What I Learned

- Building an end-to-end data pipeline
- Data cleaning techniques using Pandas
- Creating and inserting tables in SQLite
- Querying structured data with SQL
- Creating simple interactive dashboards

---

## ğŸš€ Next Steps

- Add logging and error handling
- Load data from API instead of CSVs
- Upgrade from SQLite to PostgreSQL
- Deploy dashboard using Streamlit Cloud or Render
- Schedule the pipeline with Airflow (advanced)

---